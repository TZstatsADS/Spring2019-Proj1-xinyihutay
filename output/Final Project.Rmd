---
title: ''
output:
  html_notebook: default
  html_document: default
  pdf_document: default
---
```{r,echo=FALSE}
# set path for data file
setwd("~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output")
```
>#**HappyDB :)**
>#**Why are you happy?**
>#**What makes your happy moments different from others?**
<center>By Xinyi Hu</center>  

<center>
![BoJack Horseman](../figs/bojack.gif) 
</center>  
\
\
<font size=3>
HappyDB is a large scale collection of happy moments on Amazon Mechanical Turk (MTurk) workers. And HappyDB also collected the demographic information of these workers.

Happiness is the emotion that we all share. However, things that make us happy might be relatively different from each other. Therefore, this project aims to analyze what makes people happy, and whether gender, marital status, parenthood and cultural background would differ the things and events that make people feel happy.

```{r set up,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
packages.used=c("rvest", "tibble", "ggpubr", "ggplot2","igraph","ggraph","Matrix",
                "sentimentr", "gplots", "dplyr","gcookbook","tm", "syuzhet", 
                "factoextra", "scales", "RColorBrewer","wordcloud","RANN",
                "plotly", "topicmodels","beeswarm","cluster","tidytext") 

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}
# load libraries
library("Matrix")
library("ggraph")
library("igraph")
library("ggpubr")
library("rvest")
library("tibble")
library("sentimentr")
library("gplots")
library("dplyr")
library("syuzhet")
library("factoextra")
library("scales")
library("RColorBrewer")
library("RANN")
library("plotly")
library("topicmodels")
library("beeswarm")
library("cluster") 
library("wordcloud")
library("RColorBrewer")
library("ggplot2")
library("gcookbook")
library("tm")
library("tidytext")
library("tidyverse")
library("DT")

print(R.version)
```

```{r Text Mining, warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
### Read data
clean_hm = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'  # Cleaned_hm file
demographic = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv' 
clean.hm  =  read_csv(clean_hm)
demog =  read_csv(demographic)

### Preliminary cleaning of text
corpus = VCorpus(VectorSource(clean.hm$cleaned_hm))
corpus = tm_map(corpus, stripWhitespace)  # remove white space
corpus = tm_map(corpus, content_transformer(tolower)) # convert to lower case
corpus = tm_map(corpus, removeWords, stopwords("english")) # remove stop words
corpus = tm_map(corpus, removeWords, character(0)) # remove empty words
corpus = tm_map(corpus, removePunctuation) # remove punctuations
#View(hm.demographic)

### Stem words
stemmed = tm_map(corpus, stemDocument) %>%
  tidy() %>%
  select(text)

dict = tidy(corpus) %>%
  select(text) %>%
  unnest_tokens(dictionary, text)

data("stop_words")
word = c("happy","ago","yesterday","lot","today","months","month",
                 "happier","happiest","last","week","past")

stop_words = stop_words %>%
  bind_rows(mutate(tibble(word), lexicon = "updated"))

completed = stemmed %>%
  mutate(id = row_number()) %>%
  unnest_tokens(stems, text) %>% # seperate stemmed into single words, and mark their id
  bind_cols(dict) %>% # column combine dict and stemmed, 1-to-1 matching
  anti_join(stop_words, by = c("dictionary" = "word")) # delete meaningless words

completed = completed %>%
  group_by(stems) %>%
  count(dictionary) %>%
  mutate(word = dictionary[which.max(n)]) %>%
  ungroup() %>%
  select(stems, word) %>%
  distinct() %>%
  right_join(completed) %>%
  select(-stems)

HappyMoments = completed %>%
  group_by(id) %>%  
  summarise(text = str_c(word, collapse = " ")) %>% 
  ungroup() 

HappyMoments = clean.hm %>%
  mutate(id = row_number()) %>%   
  inner_join(HappyMoments)

### Create 4 columns in HappyMoments for storing demographic information
HappyMoments$country = rep("tba", length(HappyMoments$wid))
HappyMoments$gender = rep("tba", length(HappyMoments$wid))
HappyMoments$marital = rep("tba", length(HappyMoments$wid))
HappyMoments$parenthood = rep("tba", length(HappyMoments$wid))

### matching the demographic information with the correct workers through their wid
for (i in sort(unique(HappyMoments$wid))) {
  
  index = which(HappyMoments$wid == i)
  HappyMoments[index,"country"] = demog$country[which(demog$wid == i)]
  HappyMoments[index,"gender"] = demog$gender[which(demog$wid == i)]
  HappyMoments[index,"marital"] = demog$marital[which(demog$wid == i)]
  HappyMoments[index,"parenthood"] = demog$parenthood[which(demog$wid == i)]

}

hm.demographic = HappyMoments[,-c(1,3,4,6,7,8,10)]
# write_csv(hm.demographic, "~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output/hm.demographic.csv")
# write_csv(HappyMoments, "~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output/HappyMoment.csv")

```

# Section 1: Overview of The Happy Moments

This section focuses on analyzing all happy moments regardless of workers' demographic information.

## Part 1: Wordcloud

Words that frequently appeared in MTurk workers' happy moments descriptions are: **friend**, **day**, **time**, **watched**, **family** and **home** etc. Thus, generally people will feel happy about things or events related to their friends, families, watching shows and so on.

```{r warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
clean.corpus = VCorpus(VectorSource(hm.demographic$text))
tdm.all = TermDocumentMatrix(clean.corpus)
tdm.tidy = tidy(tdm.all)
tdm.overall = summarise(group_by(tdm.tidy, term), sum(count))

wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
          scale = c(5,0.1),
          max.words = 350,
          min.freq = 5,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))
```




## Part 2: Relationships Between Words

In this part, I am interested in the relationships between words in all the happy moments descriptions. I want to whether examine which words tend to follow others immediately, or that tend to co-occur within the same documents.


```{r warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
hm.text = data_frame(line = 1:dim(HappyMoments)[1], text = HappyMoments$text)

hm_bigrams = hm.text %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) 

bigrams_separated = hm_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered = bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts = bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_graph = bigram_counts %>%
  filter(n > 150) %>%  # filter for only relatively common combinations
  graph_from_data_frame()

set.seed(2019)

a = grid::arrow(type = "closed", length = unit(.1, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.05, 'inches')) +
  geom_node_point(color = "pink", size = 3) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```

I visualize some details of the text structure. We can see that words like **visit**, **party** and **school** are often followed by the word **friend**, which means when these events are related to friends, people usually get happy. 

We also see some pairs or triplets along the outside that form common short phrases related to happy moments, such as **brought home** and **read book**.


## Part 3: Topic Modeling

Now in this part, I apply topic modeling to all happy moments corpus. I set the number of topics to be 9, which is the same as the number of 'topic_dict' in HappyDB data folder.

```{r warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
comb_hm = vector(mode = "character",length = length(unique(HappyMoments$wid)))

for (i in sort(unique(HappyMoments$wid))) {
  index = which(HappyMoments$wid == i)
  comb_hm[i] = paste(HappyMoments$text[index], collapse = " ")
}

hm.corpus = VCorpus(VectorSource(comb_hm))
dtm.all = DocumentTermMatrix(hm.corpus)
rowTotals = apply(dtm.all, 1, sum) 
dtm  = dtm.all[rowTotals> 0, ]

hm_lda = LDA(dtm, k = 9, control = list(seed = 1234))
hm_topics = tidy(hm_lda, matrix = "beta")

hm_top_terms = hm_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

hm_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = F) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```


According to the above plots and the words relationships we just found out, I sort the topics as follows:

$$
Topic\ 1: Shopping \\
Topic\ 2: Entertainment \\
Topic\ 3: People \\
Topic\ 4: Pets \\
Topic\ 5: Work \\
Topic\ 6: Exercise\\
Topic\ 7: Food \\
Topic\ 8: School \\
Topic\ 9: Family
$$

# Section 2: Analyze Happy Moments in Different Clusters

In this section, I group HappyDB data into similar categories according to Amazon MTurk workers' demographic data including gender, parenthood, marital status and continent.

## Part 1: Gender

```{r WordCloud, warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
male.hm = filter(hm.demographic,gender == "m")$text
tdm.male = TermDocumentMatrix(VCorpus(VectorSource(male.hm)))
tdm.tidy.male = tidy(tdm.male)
tdm_male = summarise(group_by(tdm.tidy.male, term), sum(count))

female.hm = filter(hm.demographic,gender == "f")$text
tdm.female = TermDocumentMatrix(VCorpus(VectorSource(female.hm)))
tdm.tidy.female = tidy(tdm.female)
tdm_female = summarise(group_by(tdm.tidy.female, term), sum(count))
```

**Male**
```{r male,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
wordcloud(tdm_female$term, tdm_female$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))
```

**Female**

```{r female,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
wordcloud(tdm_male$term, tdm_male$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))

```

The wordclouds look good, but except for words **day**, **time** and **friend**, we can hardly see other words clearly. So let's check these popular words by other visualization plot.

```{r  Gender freq ggplot,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
male.words = data_frame(line = 1:length(male.hm), text = male.hm)
male_words = male.words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 2266) %>%
  mutate(word = reorder(word, n)) 

female.words = data_frame(line = 1:length(female.hm), text = female.hm)
female_words = female.words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1725) %>%
  mutate(word = reorder(word, n)) 

p1 = ggplot(data = male_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "purple")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Male Top 10 Key Words", 
                x = "Happy Moments", y = "Frequency")


p2 = ggplot(data = female_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "red")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Female Top 10 Key Words",
                x = "Happy Moments", y = "Frequency")
        
require("gridExtra")
grid.arrange(arrangeGrob(p1, p2))
```

In both plots, the first 3 words are **day**, **time** and **friend**. And Their frequencies are almost equivalent in female data set, while in male data set, the word frequency of **friend** is much higher than the other two words. The fourth word in both data set is spouse, which is good. 

In the male data set, words **played** and **watched** rank higher than **family**. But in female data set, words related to family and home are in the front. So you can see the differences of happy moments between female and male.

## Part 2: Parenthood

```{r Parenthood WordCloud,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
yes.hm = filter(hm.demographic,parenthood == "y")$text
tdm.yes = TermDocumentMatrix(VCorpus(VectorSource(yes.hm)))
tdm.tidy.yes = tidy(tdm.yes)
tdm_yes = summarise(group_by(tdm.tidy.yes, term), sum(count))

no.hm = filter(hm.demographic,parenthood == "n")$text
tdm.no = TermDocumentMatrix(VCorpus(VectorSource(no.hm)))
tdm.tidy.no = tidy(tdm.no)
tdm_no = summarise(group_by(tdm.tidy.no, term), sum(count))

wordcloud(tdm_yes$term, tdm_yes$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))

wordcloud(tdm_no$term, tdm_no$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))

```

The popular words in these two clusters are apparently different. For those who have kids, although **day**, **time** and **friends** are still the frequent words in their happy moments descriptions, family related words like **daughter** and **son** contribute to their happy moments a lot. 

While in the no-child cluster, except for words **day**, **time** and **friends**, we can see words related to entertainment show up frequently, such as **game**, **played** and **watched**. And this result is quite reasonable.

```{r  Parenthood ggplot,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
yes_words = data_frame(line = 1:length(yes.hm), text = yes.hm)
yes_words = yes_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1749) %>%
  mutate(word = reorder(word, n)) 

no_words = data_frame(line = 1:length(no.hm), text = no.hm)
no_words = no_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 2226) %>%
  mutate(word = reorder(word, n)) 

p3 = ggplot(data = yes_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "orange")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Parenthood Top 10 Key Words", 
                x = "Happy Moments", y = "Frequency")

p4 = ggplot(data = no_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "lightblue")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Childlessness Top 10 Key Words", 
                x = "Happy Moments", y = "Frequency")
        
grid.arrange(arrangeGrob(p3, p4))
```

## Part 3: Marital Status

```{r Marital ggplots,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
married.hm = filter(hm.demographic,marital == "married")$text
tdm.married = TermDocumentMatrix(VCorpus(VectorSource(married.hm)))
m.married = as.matrix(tdm.married)
v.married = sort(rowSums(m.married),decreasing=TRUE)
d.married = data.frame(word = names(v.married),freq=v.married)

single.hm = filter(hm.demographic,marital == "single")$text
single_words = data_frame(line = 1:length(single.hm), text = single.hm)
single_words = single_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1982) %>%
  mutate(word = reorder(word, n)) 

divorced.hm = filter(hm.demographic,marital == "divorced")$text
tdm.divorced = TermDocumentMatrix(VCorpus(VectorSource(divorced.hm)))
m.divorced = as.matrix(tdm.divorced)
v.divorced = sort(rowSums(m.divorced),decreasing=TRUE)
d.divorced = data.frame(word = names(v.divorced),freq=v.divorced)

separated.hm = filter(hm.demographic,marital == "separated")$text
tdm.separated = TermDocumentMatrix(VCorpus(VectorSource(separated.hm)))
m.separated = as.matrix(tdm.separated)
v.separated = sort(rowSums(m.separated),decreasing=TRUE)
d.separated = data.frame(word = names(v.separated),freq=v.separated)

widowed.hm = filter(hm.demographic,marital == "widowed")$text
tdm.widowed = TermDocumentMatrix(VCorpus(VectorSource(widowed.hm)))
m.widowed = as.matrix(tdm.widowed)
v.widowed = sort(rowSums(m.widowed),decreasing=TRUE)
d.widowed = data.frame(word = names(v.widowed),freq=v.widowed)

p5 = ggplot(data = d.married[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "pink")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Married", x = "Happy Moments",
                y = "Frequency")

p6 = ggplot(data = single_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "lightblue")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Single", x = "Happy Moments", 
                y = "Frequency")

p7 = ggplot(data = d.divorced[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "grey")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Divorced", x = "Happy Moments", 
                y = "Frequency")

p8 = ggplot(data = d.separated[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "darkgreen")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Separated", x = "Happy Moments", 
                y = "Frequency")

p9 = ggplot(data = d.widowed[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "black")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Widowed", x = "Happy Moments", 
                y = "Frequency")
ggarrange(p5, p6, p7, p8, p9, nrow = 2, ncol = 3)
```

In each marital status, words **day**, **time** and **friends** are still frequently appear. And in cluster single, words related to entertainment are popular. In cluster married, family related words rank higher than the words **watched**, which suggests that positive things or events related to family usually make married people happy and these happy moments tend to be remembered.

In clusters divorced and separated, words **daughter**, **son** and **watched** rank high, while words home ranks lower. To my mind, this makes sense since divorce is a formal ending of a marriage, and separated couples do not have strong connection to their spouses as married people do, or maybe some of these separated couples are processing divorce. So in this case, doing some entertainments and their kids are the reasons why they are happy.


## Part 4: Continent

In this final part, I sort Amazon MTurk workers into six main continents: Asia, Africa, Europe, Northern America, Southern America and Oceania. I want to know wether people's cultural background will cause differences in terms of happiness.
\
```{r Countries Pre-processing,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
nation.abbre = read.csv("country abbreviation.csv", header = T)

na = which(is.na(hm.demographic$country))  
hm.country = hm.demographic[-na,]

mark = c()
for (i in 1:length(hm.country$country)){
    mark[i] = grep(pattern = hm.country$country[i], nation.abbre$Abbrevation)
}

hm.country$Region = as.character(nation.abbre$Region[mark])

region = VCorpus(VectorSource(hm.country$Region))
region = tm_map(region, stripWhitespace)  # remove white space
reg = tidy(region)
hm.country$Region = reg$text

AF = which(hm.country$Region == "NORTHERN AFRICA " | hm.country$Region == "SUB-SAHARAN AFRICA ")

AS = which(hm.country$Region == "ASIA (EX. NEAR EAST) " | hm.country$Region == "NEAR EAST " | hm.country$country == "ARM" | hm.country$country == "KAZ")

EU =  which(hm.country$Region == "WESTERN EUROPE "  | hm.country$Region == "EASTERN EUROPE " | hm.country$Region == "BALTICS " | hm.country$country == "MDA" | hm.country$country == "UKR" | hm.country$country == "RUS")

N.A = which(hm.country$Region == "NORTHERN AMERICA ")

S.A = which(hm.country$Region == "LATIN AMER. & CARIB " )

OC = which(hm.country$Region == "OCEANIA ")
```

```{r Sort continents,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
AF.hm = hm.country$text[AF]
tdm.AF = TermDocumentMatrix(VCorpus(VectorSource(AF.hm)))
m.AF = as.matrix(tdm.AF)
v.AF = sort(rowSums(m.AF),decreasing=TRUE)
d.AF = data.frame(word = names(v.AF)[1:10],freq=round(100*v.AF[1:10]/sum(v.AF),2))

AS.hm = hm.country$text[AS]
tdm.AS = TermDocumentMatrix(VCorpus(VectorSource(AS.hm)))
m.AS = as.matrix(tdm.AS)
v.AS = sort(rowSums(m.AS),decreasing=TRUE)
d.AS = data.frame(word = names(v.AS)[1:10],freq=round(100*v.AS[1:10]/sum(v.AS),2))

EU.hm = hm.country$text[EU]
tdm.EU = TermDocumentMatrix(VCorpus(VectorSource(EU.hm)))
m.EU = as.matrix(tdm.EU)
v.EU = sort(rowSums(m.EU),decreasing=TRUE)
d.EU = data.frame(word = names(v.EU)[1:10],freq=round(100*v.EU[1:10]/sum(v.EU),2))

NA.hm = hm.country$text[N.A]
NA_words = data_frame(line = 1:length(NA.hm), text = NA.hm)
NA_words = NA_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) 

total = sum(NA_words$n) # total sum of words in NA_words

NA_words = NA_words %>%
  filter(n > 2972) %>%
  mutate(word = reorder(word, n)) 

count = as.numeric(NA_words$n)
d.NA = data.frame(word = as.character(NA_words$word), freq=round(100*count/total,2))

SA.hm = hm.country$text[S.A]
tdm.SA = TermDocumentMatrix(VCorpus(VectorSource(SA.hm)))
m.SA = as.matrix(tdm.SA)
v.SA = sort(rowSums(m.SA),decreasing=TRUE)
d.SA = data.frame(word = names(v.SA)[1:10],freq=round(100*v.SA[1:10]/sum(v.SA),2))

OC.hm = hm.country$text[OC]
tdm.OC = TermDocumentMatrix(VCorpus(VectorSource(OC.hm)))
m.OC = as.matrix(tdm.OC)
v.OC = sort(rowSums(m.OC),decreasing=TRUE)
d.OC = data.frame(word = names(v.OC)[1:10],freq=round(100*v.OC[1:10]/sum(v.OC),2))

hm.region = data.frame(AF = d.AF$word, 
                       AS = d.AS$word, 
                       EU = d.EU$word, 
                       N.A = d.NA$word, 
                       SA = d.SA$word, 
                       OC = d.OC$word)

hm.reg.freq = data.frame(AF.freq = d.AF$freq,
                         AS.freq = d.AS$freq,
                         EU.freq = d.EU$freq,
                         NA.freq = d.NA$freq,
                         SA.freq = d.SA$freq,
                         OC.freq = d.OC$freq)
```

```{r WorldMap,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
af.nation = unique(hm.country$country[AF])
as.nation = unique(hm.country$country[AS])
eu.nation = unique(hm.country$country[EU])
na.nation = unique(hm.country$country[N.A])
sa.nation = unique(hm.country$country[S.A])
oc.nation = unique(hm.country$country[OC])

continent = c("Africa", "Asia", "Europe", "Northern America", "Southern America", "Oceania")

Pop = c(length(AF),length(AS),length(EU),length(N.A),length(S.A),length(OC))

nation.in.continent =c(length(af.nation),length(as.nation),length(eu.nation),length(na.nation),length(sa.nation),length(oc.nation))


hover = character(6)

for(i in 1:6){
  hover[i] = paste( '<b>', continent[i],':<br>', 
                    paste('   ','</b>',hm.region[[i]], ': ', hm.reg.freq[[i]],'% <br>',
                          collapse=""),
                    collapse="")
}

pop = rep(Pop,nation.in.continent)
cont = rep(continent,nation.in.continent)
all.nation = c(af.nation,as.nation,eu.nation,na.nation,sa.nation,oc.nation)
rank.text = rep(hover,nation.in.continent)
dataformap = data.frame(Nation = all.nation,
                        Worker = pop,
                        Continent = cont,
                        text = rank.text)

l = list(color = toRGB("darkgrey"), width = 0.5)

g = list(
  showframe = FALSE,
  showcoastlines = FALSE,
  projection = list(type = 'Mercator')
)

p = plot_geo(dataformap) %>%
  add_trace(
    z = ~Worker, color = ~Worker, colors = 'Blues',
    text = ~text, locations = ~Nation, marker = list(line = l)
  ) %>%
  colorbar(title = 'Number of Amazon MTurk Workers') %>%
  layout(
    title = 'Top 10 key words of Happy Moments in Each Continent',
    geo = g,
    autosize = FALSE,
    width = 900,
    margin = list(t=20, l=0, r=0, d=0)
  )

p
```

Compared with other continents, workers from Africa talked about their friends a lot in their happy moments descriptions. And the word **job** appears only in Africa cluster.

In the Asia cluster, we only see one word that is kind of related to entertainment, that is **enjoyed**.And many Asian workers mentioned the word **birthday** which only appears in Asia cluster.  

The first 10 popular words of workers from Northern America are somewhat similar to that of Europe. They all contain a couple of words related to entertainments like **won**, **played**, **watched**, and these words rank relatively high. But in terms of people and family, Europe cluster contains word **girlfriend** followed by the word family, while Northern America cluster contains words **home** and **daughter**. Besides, the word **dinner** shows up in Northern America cluster, it might suggest that dinner is something important in Northern American culture.

Let's move on to the Southern America cluster. Workers from Southern America talked a lot about shopping and entertainments in their happy moments, because this cluster contains words **buy**, **played** and **game**, and notice that the word **buy** ranks high.

Finally, let's check Oceania cluster. The top 10 popular words of happy moments in this cluster is very different from the rest of 5 clusters. Word **friend**, **day** and **time** do not rank very high. And we can see words like **read** and **dog** appear in this cluster. 
```{r ggplot,warning=FALSE,error=FALSE,echo=FALSE,message=FALSE}
p.af = ggplot(data = d.AF,aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "pink")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Africa", x = "Happy Moments",
                y = "Frequency")

p.as =  ggplot(data = d.AS,aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "orange")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Asia", x = "Happy Moments",
                y = "Frequency")
  
p.eu =  ggplot(data = d.EU,aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "red")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Europe", x = "Happy Moments",
                y = "Frequency")
  
p.na = ggplot(data = NA_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "purple")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Northern America", x = "Happy Moments", 
                y = "Frequency")
p.sa =  ggplot(data = d.SA,aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "blue")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Southern America", x = "Happy Moments",
                y = "Frequency")

p.oc =  ggplot(data = d.OC,aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "lightblue")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Oceania", x = "Happy Moments",
                y = "Frequency")
ggarrange(p.af, p.as, p.eu, p.na, p.sa, p.oc, ncol = 3, nrow = 2)
```

However, as you can see in the y-lab, it reveals that the number of workers from Africa, Southern America and Oceania is quite small, Oceania in particular. So the analysis on popular words in these three clusters cannot give us a typical conclusion.

> ## Conclusions
<center>
![Happy](../figs/happy.gif) 
</center>  



* Generally, people feel happy because they spend positive moments with their friends and families. 

* Events that do not have friends and families involved can also create happiness, such as saved money, walked dog and watched tv etc.

* Gender, parenthood, marital status and cultural background do vary the factors that make people feel happy.


<font size=1.5>
**Reference:**   

1. Country Code(ISO 3): From<https://unstats.un.org/unsd/tradekb/knowledgebase/country-code>   

2. Countries of The World: From<www.statvision.com/webinars/countries%20of%20the%20world.xls>  

3. Bojack Horseman: From<https://tenor.com/view/awesome-bojack-horseman-gif-9606938> </front>





