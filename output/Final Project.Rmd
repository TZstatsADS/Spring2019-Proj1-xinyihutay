---
title: "R Notebook"
output: html_notebook
---

```{r set up, message=FALSE, warning=FALSE}
packages.used=c("rvest", "tibble", "ggpubr", "ggplot2","igraph","ggraph",
                "sentimentr", "gplots", "dplyr","gcookbook","tm", "syuzhet", 
                "factoextra", "scales", "RColorBrewer","wordcloud","RANN",
                "plotly", "topicmodels","beeswarm","cluster","tidytext") 

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}
# load libraries
library("ggraph")
library("igraph")
library("ggpubr")
library("rvest")
library("tibble")
library("sentimentr")
library("gplots")
library("dplyr")
library("syuzhet")
library("factoextra")
library("scales")
library("RColorBrewer")
library("RANN")
library("plotly")
library("topicmodels")
library("beeswarm")
library("cluster") 
library("wordcloud")
library("RColorBrewer")
library("ggplot2")
library("gcookbook")
library("tm")
library("tidytext")
library("tidyverse")
library("DT")

print(R.version)
```

# Pre-processing 

```{r read data, warning=FALSE, message=FALSE}
clean_hm = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'  # Cleaned_hm file
demographic = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv' 
clean.hm  =  read_csv(clean_hm)
demog =  read_csv(demographic)
```

```{r Clean text}
corpus = VCorpus(VectorSource(clean.hm$cleaned_hm))
corpus = tm_map(corpus, stripWhitespace)  # remove white space
corpus = tm_map(corpus, content_transformer(tolower)) # convert to lower case
corpus = tm_map(corpus, removeWords, stopwords("english")) # remove stop words
corpus = tm_map(corpus, removeWords, character(0)) # remove empty words
corpus = tm_map(corpus, removePunctuation) # remove punctuations
View(hm.demographic)
```

```{r Stemming words}
stemmed = tm_map(corpus, stemDocument) %>%
  tidy() %>%
  select(text)
```

```{r Dictionary remove stop words}
dict = tidy(corpus) %>%
  select(text) %>%
  unnest_tokens(dictionary, text)

data("stop_words")
word = c("happy","ago","yesterday","lot","today","months","month",
                 "happier","happiest","last","week","past")

stop_words = stop_words %>%
  bind_rows(mutate(tibble(word), lexicon = "updated"))
```

```{r tidy stems with dictionary}
completed = stemmed %>%
  mutate(id = row_number()) %>%
  unnest_tokens(stems, text) %>% # seperate stemmed into single words, and mark their id
  bind_cols(dict) %>% # column combine dict and stemmed, 1-to-1 matching
  anti_join(stop_words, by = c("dictionary" = "word")) # delete meaningless words
```

```{r stem completion, warning=FALSE, message=FALSE}
completed = completed %>%
  group_by(stems) %>%
  count(dictionary) %>%
  mutate(word = dictionary[which.max(n)]) %>%
  ungroup() %>%
  select(stems, word) %>%
  distinct() %>%
  right_join(completed) %>%
  select(-stems)
```

```{r reverse unnest}
HappyMoments = completed %>%
  group_by(id) %>%  
  summarise(text = str_c(word, collapse = " ")) %>% 
  ungroup() 

HappyMoments = clean.hm %>%
  mutate(id = row_number()) %>%   
  inner_join(HappyMoments)

HappyMoments = HappyMoments[,-c(1,4)]

HappyMoments$country = rep("tba", length(HappyMoments$wid))
HappyMoments$gender = rep("tba", length(HappyMoments$wid))
HappyMoments$marital = rep("tba", length(HappyMoments$wid))
HappyMoments$parenthood = rep("tba", length(HappyMoments$wid))

for (i in sort(unique(HappyMoments$wid))) {
  
  index = which(HappyMoments$wid == i)
  HappyMoments[index,"country"] = demog$country[which(demog$wid == i)]
  HappyMoments[index,"gender"] = demog$gender[which(demog$wid == i)]
  HappyMoments[index,"marital"] = demog$marital[which(demog$wid == i)]
  HappyMoments[index,"parenthood"] = demog$parenthood[which(demog$wid == i)]

}
hm.demographic = HappyMoments[,-8]
#datatable(hm.demographic)
dim(hm.demog)

hm.demographic = hm.demog[-which(is.na(hm.demographic$country)),]
hm.demographic = hm.demographic[-which(is.na(hm.demographic$gender)),]
hm.demographic = hm.demographic[-which(is.na(hm.demographic$marital)),]
hm.demographic = hm.demographic[-which(is.na(hm.demographic$parenthood)),]

dim(hm.demographic)


# View(hm.demographic)
write_csv(hm.demographic, "~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output/hm.demographic.csv")

# setwd("~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output")
#processed_moments = read.csv("processed_moments.csv", header = T)
#View(processed_moments)
#length(unique(processed_moments$wid))
#length(unique(HappyMoments$wid))
#length(unique(demog$wid))
#hm.demog = read.csv("hm.demographic.csv")
#mode(hm.demog)
#View(hm.demog)
```

# Overview
```{r WordCloud }

clean.corpus = VCorpus(VectorSource(hm.demographic$text))
tdm.all = TermDocumentMatrix(clean.corpus)
tdm.tidy = tidy(tdm.all)
tdm.overall = summarise(group_by(tdm.tidy, term), sum(count))

wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
          scale = c(5,0.1),
          max.words = 500,
          min.freq = 5,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))

```

```{r Relationships between words grams and correlations}
hm.text = data_frame(line = 1:dim(HappyMoments)[1], text = HappyMoments$text)

hm_bigrams = hm.text %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) 

bigrams_separated = hm_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered = bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts = bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_graph = bigram_counts %>%
  filter(n > 150) %>%  # filter for only relatively common combinations
  graph_from_data_frame()

set.seed(2019)

a = grid::arrow(type = "closed", length = unit(.1, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.05, 'inches')) +
  geom_node_point(color = "pink", size = 3) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```

# Classification 
```{r WordCloud Gender}
male.hm = filter(hm.demographic,gender == "m")$text
tdm.male = TermDocumentMatrix(VCorpus(VectorSource(male.hm)))
tdm.tidy.male = tidy(tdm.male)
tdm_male = summarise(group_by(tdm.tidy.male, term), sum(count))

wordcloud(tdm_male$term, tdm_male$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))


female.hm = filter(hm.demographic,gender == "f")$text
tdm.female = TermDocumentMatrix(VCorpus(VectorSource(female.hm)))
tdm.tidy.female = tidy(tdm.female)
tdm_female = summarise(group_by(tdm.tidy.female, term), sum(count))
wordcloud(tdm_female$term, tdm_female$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))
```

```{r  Gender dataframe ggplot}
male_words = data_frame(line = 1:length(male.hm), text = male.hm)
male_words = male_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 2266) %>%
  mutate(word = reorder(word, n)) 


female_words = data_frame(line = 1:length(female.hm), text = female.hm)
female_words = female_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1725) %>%
  mutate(word = reorder(word, n)) 

p1 = ggplot(data = male_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "purple")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Male Top 10 Key Words", 
                x = "Happy Moments", y = "Frequency")


p2 = ggplot(data = female_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "red")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Female Top 10 Key Words",
                x = "Happy Moments", y = "Frequency")
        
require("gridExtra")
grid.arrange(arrangeGrob(p1, p2))
```

```{r WordCloud Parenthood}
yes.hm = filter(hm.demographic,parenthood == "y")$text
tdm.yes = TermDocumentMatrix(VCorpus(VectorSource(yes.hm)))
tdm.tidy.yes = tidy(tdm.yes)
tdm_yes = summarise(group_by(tdm.tidy.yes, term), sum(count))
wordcloud(tdm_yes$term, tdm_yes$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))

no.hm = filter(hm.demographic,parenthood == "n")$text
tdm.no = TermDocumentMatrix(VCorpus(VectorSource(no.hm)))
tdm.tidy.no = tidy(tdm.no)
tdm_no = summarise(group_by(tdm.tidy.no, term), sum(count))
wordcloud(tdm_no$term, tdm_no$`sum(count)`,
          scale = c(5,0.1),
          max.words = 100,
          min.freq = 1,
          random.order = FALSE,
          rot.per = 0.3,
          use.r.layout = T,
          random.color = FALSE,
          colors = brewer.pal(8,"Accent"))


```

```{r  Parenthood ggplot dataframe}
yes_words = data_frame(line = 1:length(yes.hm), text = yes.hm)
yes_words = yes_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1749) %>%
  mutate(word = reorder(word, n)) 

no_words = data_frame(line = 1:length(no.hm), text = no.hm)
no_words = no_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 2226) %>%
  mutate(word = reorder(word, n)) 

p3 = ggplot(data = yes_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "orange")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Parenthood Top 10 Key Words", 
                x = "Happy Moments", y = "Frequency")

p4 = ggplot(data = no_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "lightblue")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Childlessness Top 10 Key Words", 
                x = "Happy Moments", y = "Frequency")
        
grid.arrange(arrangeGrob(p3, p4))
```

```{r Marital ggplots}
unique(hm.demographic$marital)

married.hm = filter(hm.demographic,marital == "married")$text
tdm.married = TermDocumentMatrix(VCorpus(VectorSource(married.hm)))
m.married = as.matrix(tdm.married)
v.married = sort(rowSums(m.married),decreasing=TRUE)
d.married = data.frame(word = names(v.married),freq=v.married)

single.hm = filter(hm.demographic,marital == "single")$text
single_words = data_frame(line = 1:length(single.hm), text = single.hm)
single_words = single_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1982) %>%
  mutate(word = reorder(word, n)) 

divorced.hm = filter(hm.demographic,marital == "divorced")$text
tdm.divorced = TermDocumentMatrix(VCorpus(VectorSource(divorced.hm)))
m.divorced = as.matrix(tdm.divorced)
v.divorced = sort(rowSums(m.divorced),decreasing=TRUE)
d.divorced = data.frame(word = names(v.divorced),freq=v.divorced)

separated.hm = filter(hm.demographic,marital == "separated")$text
tdm.separated = TermDocumentMatrix(VCorpus(VectorSource(separated.hm)))
m.separated = as.matrix(tdm.separated)
v.separated = sort(rowSums(m.separated),decreasing=TRUE)
d.separated = data.frame(word = names(v.separated),freq=v.separated)

widowed.hm = filter(hm.demographic,marital == "widowed")$text
tdm.widowed = TermDocumentMatrix(VCorpus(VectorSource(widowed.hm)))
m.widowed = as.matrix(tdm.widowed)
v.widowed = sort(rowSums(m.widowed),decreasing=TRUE)
d.widowed = data.frame(word = names(v.widowed),freq=v.widowed)

p5 = ggplot(data = d.married[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "pink")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Married", x = "Happy Moments",
                y = "Frequency")

p6 = ggplot(data = single_words,aes(x = reorder(word,-n),
                                     y = n))+
           geom_bar(stat = "identity", fill = "lightblue")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Single", x = "Happy Moments", 
                y = "Frequency")

p7 = ggplot(data = d.divorced[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "grey")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Divorced", x = "Happy Moments", 
                y = "Frequency")

p8 = ggplot(data = d.separated[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "darkgreen")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Separated", x = "Happy Moments", 
                y = "Frequency")

p9 = ggplot(data = d.widowed[1:10,],aes(x = reorder(word,-freq),
                                     y = freq))+
           geom_bar(stat = "identity", fill = "black")+
           theme(axis.text.x = element_text(angle = 45, hjust = 1))+
           labs(title = "Widowed", x = "Happy Moments", 
                y = "Frequency")


ggarrange(p5, p6, p7, p8, p9,common.legend=TRUE,legend = 'right')
```

```{r Countries Pre-processing}
# Pre-processing regions and countries data
nation.abbre = read.csv("country abbreviation.csv", header = T)
View(nation.abbre)

na = which(is.na(hm.demographic$country))  
hm.country = hm.demographic[-na,]
sum(is.na(hm.country$country))
dim(hm.demographic)
dim(hm.country)

mark = c()
for (i in 1:length(hm.country$country)){
    mark[i] = grep(pattern = hm.country$country[i], nation.abbre$Abbrevation)
}

length(mark)

hm.country$Region = as.character(nation.abbre$Region[mark])

region = VCorpus(VectorSource(hm.country$Region))
region = tm_map(region, stripWhitespace)  # remove white space
reg = tidy(region)
hm.country$Region = reg$text
unique(hm.country$Region)

AF = which(hm.country$Region == "NORTHERN AFRICA " | hm.country$Region == "SUB-SAHARAN AFRICA ")
AS = which(hm.country$Region == "ASIA (EX. NEAR EAST) " | hm.country$Region == "NEAR EAST " | hm.country$country == "ARM" | hm.country$country == "KAZ")
EU =  which(hm.country$Region == "WESTERN EUROPE "  | hm.country$Region == "EASTERN EUROPE " | hm.country$Region == "BALTICS " | hm.country$country == "MDA" | hm.country$country == "UKR" | hm.country$country == "RUS")
N.A = which(hm.country$Region == "NORTHERN AMERICA ")
S.A = which(hm.country$Region == "LATIN AMER. & CARIB " )
OC = which(hm.country$Region == "OCEANIA ")
```

```{r Count}
AF.hm = hm.country$text[AF]
tdm.AF = TermDocumentMatrix(VCorpus(VectorSource(AF.hm)))
m.AF = as.matrix(tdm.AF)
v.AF = sort(rowSums(m.AF),decreasing=TRUE)
d.AF = data.frame(word = names(v.AF)[1:10],freq=v.AF[1:10])

AS.hm = hm.country$text[AS]
tdm.AS = TermDocumentMatrix(VCorpus(VectorSource(AS.hm)))
m.AS = as.matrix(tdm.AS)
v.AS = sort(rowSums(m.AS),decreasing=TRUE)
d.AS = data.frame(word = names(v.AS)[1:10],freq=v.AS[1:10])

EU.hm = hm.country$text[EU]
tdm.EU = TermDocumentMatrix(VCorpus(VectorSource(EU.hm)))
m.EU = as.matrix(tdm.EU)
v.EU = sort(rowSums(m.EU),decreasing=TRUE)
d.EU = data.frame(word = names(v.EU)[1:10],freq=v.EU[1:10])

NA.hm = hm.country$text[N.A]
NA_words = data_frame(line = 1:length(NA.hm), text = NA.hm)
NA_words = NA_words %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 2972) %>%
  mutate(word = reorder(word, n)) 

SA.hm = hm.country$text[S.A]
tdm.SA = TermDocumentMatrix(VCorpus(VectorSource(SA.hm)))
m.SA = as.matrix(tdm.SA)
v.SA = sort(rowSums(m.SA),decreasing=TRUE)
d.SA = data.frame(word = names(v.SA)[1:10],freq=v.SA[1:10])

OC.hm = hm.country$text[OC]
tdm.OC = TermDocumentMatrix(VCorpus(VectorSource(OC.hm)))
m.OC = as.matrix(tdm.OC)
v.OC = sort(rowSums(m.OC),decreasing=TRUE)
d.OC = data.frame(word = names(v.OC)[1:10],freq=v.OC[1:10])

hm.region = data.frame(AF = d.AF$word, AS = d.AS$word, EU = d.EU$word, N.A = NA_words$word, SA = d.SA$word, OC = d.OC$word)
View(hm.region)
```

```{r WorldMap}
af.nation = unique(hm.country$country[AF])
as.nation = unique(hm.country$country[AS])
eu.nation = unique(hm.country$country[EU])
na.nation = unique(hm.country$country[N.A])
sa.nation = unique(hm.country$country[S.A])
oc.nation = unique(hm.country$country[OC])

continent = c("Africa", "Asia", "Europe", "Northern America", "Southern America", "Oceania")

Pop = c(length(AF),length(AS),length(EU),length(N.A),length(S.A),length(OC))

nation.in.continent =c(length(af.nation),length(as.nation),length(eu.nation),length(na.nation),length(sa.nation),length(oc.nation))


hover = character(6)

for(i in 1:6){
  hover[i] = paste( '<b>', continent[i],':<br>', 
                    paste('   ','</b>',hm.region[[i]], '<br>',
                          collapse=""),
                    collapse="")
}

pop = rep(Pop,nation.in.continent)
cont = rep(continent,nation.in.continent)
all.nation = c(af.nation,as.nation,eu.nation,na.nation,sa.nation,oc.nation)
rank.text = rep(hover,nation.in.continent)

dataformap = data.frame(Nation = all.nation,
                        Worker = pop,
                        Continent = cont,
                        text = rank.text)
dim(dataformap)
View(dataformap)

l = list(color = toRGB("darkgrey"), width = 0.5)

g = list(
  showframe = FALSE,
  showcoastlines = FALSE,
  projection = list(type = 'Mercator')
)

p = plot_geo(dataformap) %>%
  add_trace(
    z = ~Worker, color = ~Worker, colors = 'Blues',
    text = ~text, locations = ~Nation, marker = list(line = l)
  ) %>%
  colorbar(title = 'Number of Amazon MTurk Workers') %>%
  layout(
    title = 'Top 10 key words of Happy Moments in Each Continent',
    geo = g
  )
p

```


