rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
yes_words = data_frame(line = 1:length(yes.hm), text = yes.hm)
yes_words = yes_words %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(n > 1749) %>%
mutate(word = reorder(word, n))
no_words = data_frame(line = 1:length(no.hm), text = no.hm)
no_words = no_words %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(n > 2226) %>%
mutate(word = reorder(word, n))
p3 = ggplot(data = yes_words,aes(x = reorder(word,-n),
y = n))+
geom_bar(stat = "identity", fill = "orange")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Parenthood Top 10 Key Words",
x = "Happy Moments", y = "Frequency")
p4 = ggplot(data = no_words,aes(x = reorder(word,-n),
y = n))+
geom_bar(stat = "identity", fill = "lightblue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Childlessness Top 10 Key Words",
x = "Happy Moments", y = "Frequency")
grid.arrange(arrangeGrob(p3, p4))
married.hm = filter(hm.demographic,marital == "married")$text
tdm.married = TermDocumentMatrix(VCorpus(VectorSource(married.hm)))
m.married = as.matrix(tdm.married)
v.married = sort(rowSums(m.married),decreasing=TRUE)
d.married = data.frame(word = names(v.married),freq=v.married)
single.hm = filter(hm.demographic,marital == "single")$text
single_words = data_frame(line = 1:length(single.hm), text = single.hm)
single_words = single_words %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(n > 1982) %>%
mutate(word = reorder(word, n))
divorced.hm = filter(hm.demographic,marital == "divorced")$text
tdm.divorced = TermDocumentMatrix(VCorpus(VectorSource(divorced.hm)))
m.divorced = as.matrix(tdm.divorced)
v.divorced = sort(rowSums(m.divorced),decreasing=TRUE)
d.divorced = data.frame(word = names(v.divorced),freq=v.divorced)
separated.hm = filter(hm.demographic,marital == "separated")$text
tdm.separated = TermDocumentMatrix(VCorpus(VectorSource(separated.hm)))
m.separated = as.matrix(tdm.separated)
v.separated = sort(rowSums(m.separated),decreasing=TRUE)
d.separated = data.frame(word = names(v.separated),freq=v.separated)
widowed.hm = filter(hm.demographic,marital == "widowed")$text
tdm.widowed = TermDocumentMatrix(VCorpus(VectorSource(widowed.hm)))
m.widowed = as.matrix(tdm.widowed)
v.widowed = sort(rowSums(m.widowed),decreasing=TRUE)
d.widowed = data.frame(word = names(v.widowed),freq=v.widowed)
p5 = ggplot(data = d.married[1:10,],aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "pink")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Married", x = "Happy Moments",
y = "Frequency")
p6 = ggplot(data = single_words,aes(x = reorder(word,-n),
y = n))+
geom_bar(stat = "identity", fill = "lightblue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Single", x = "Happy Moments",
y = "Frequency")
p7 = ggplot(data = d.divorced[1:10,],aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "grey")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Divorced", x = "Happy Moments",
y = "Frequency")
p8 = ggplot(data = d.separated[1:10,],aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "darkgreen")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Separated", x = "Happy Moments",
y = "Frequency")
p9 = ggplot(data = d.widowed[1:10,],aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "black")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Widowed", x = "Happy Moments",
y = "Frequency")
ggarrange(p5, p6, p7, p8, p9, nrow = 2, ncol = 3)
nation.abbre = read.csv("country abbreviation.csv", header = T)
# set path for data file
setwd("~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output")
nation.abbre = read.csv("country abbreviation.csv", header = T)
nation.abbre = read.csv("country abbreviation.csv", header = T)
nation.abbre = read.csv("country abbreviation.csv", header = T)
na = which(is.na(hm.demographic$country))
hm.country = hm.demographic[-na,]
mark = c()
for (i in 1:length(hm.country$country)){
mark[i] = grep(pattern = hm.country$country[i], nation.abbre$Abbrevation)
}
hm.country$Region = as.character(nation.abbre$Region[mark])
region = VCorpus(VectorSource(hm.country$Region))
region = tm_map(region, stripWhitespace)  # remove white space
reg = tidy(region)
hm.country$Region = reg$text
AF = which(hm.country$Region == "NORTHERN AFRICA " | hm.country$Region == "SUB-SAHARAN AFRICA ")
AS = which(hm.country$Region == "ASIA (EX. NEAR EAST) " | hm.country$Region == "NEAR EAST " | hm.country$country == "ARM" | hm.country$country == "KAZ")
EU =  which(hm.country$Region == "WESTERN EUROPE "  | hm.country$Region == "EASTERN EUROPE " | hm.country$Region == "BALTICS " | hm.country$country == "MDA" | hm.country$country == "UKR" | hm.country$country == "RUS")
N.A = which(hm.country$Region == "NORTHERN AMERICA ")
S.A = which(hm.country$Region == "LATIN AMER. & CARIB " )
OC = which(hm.country$Region == "OCEANIA ")
AF.hm = hm.country$text[AF]
tdm.AF = TermDocumentMatrix(VCorpus(VectorSource(AF.hm)))
m.AF = as.matrix(tdm.AF)
v.AF = sort(rowSums(m.AF),decreasing=TRUE)
d.AF = data.frame(word = names(v.AF)[1:10],freq=round(100*v.AF[1:10]/sum(v.AF),2))
AS.hm = hm.country$text[AS]
tdm.AS = TermDocumentMatrix(VCorpus(VectorSource(AS.hm)))
m.AS = as.matrix(tdm.AS)
v.AS = sort(rowSums(m.AS),decreasing=TRUE)
d.AS = data.frame(word = names(v.AS)[1:10],freq=round(100*v.AS[1:10]/sum(v.AS),2))
EU.hm = hm.country$text[EU]
tdm.EU = TermDocumentMatrix(VCorpus(VectorSource(EU.hm)))
m.EU = as.matrix(tdm.EU)
v.EU = sort(rowSums(m.EU),decreasing=TRUE)
d.EU = data.frame(word = names(v.EU)[1:10],freq=round(100*v.EU[1:10]/sum(v.EU),2))
NA.hm = hm.country$text[N.A]
NA_words = data_frame(line = 1:length(NA.hm), text = NA.hm)
NA_words = NA_words %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE)
total = sum(NA_words$n) # total sum of words in NA_words
NA_words = NA_words %>%
filter(n > 2972) %>%
mutate(word = reorder(word, n))
count = as.numeric(NA_words$n)
d.NA = data.frame(word = as.character(NA_words$word), freq=round(100*count/total,2))
SA.hm = hm.country$text[S.A]
tdm.SA = TermDocumentMatrix(VCorpus(VectorSource(SA.hm)))
m.SA = as.matrix(tdm.SA)
v.SA = sort(rowSums(m.SA),decreasing=TRUE)
d.SA = data.frame(word = names(v.SA)[1:10],freq=round(100*v.SA[1:10]/sum(v.SA),2))
OC.hm = hm.country$text[OC]
tdm.OC = TermDocumentMatrix(VCorpus(VectorSource(OC.hm)))
m.OC = as.matrix(tdm.OC)
v.OC = sort(rowSums(m.OC),decreasing=TRUE)
d.OC = data.frame(word = names(v.OC)[1:10],freq=round(100*v.OC[1:10]/sum(v.OC),2))
hm.region = data.frame(AF = d.AF$word,
AS = d.AS$word,
EU = d.EU$word,
N.A = d.NA$word,
SA = d.SA$word,
OC = d.OC$word)
hm.reg.freq = data.frame(AF.freq = d.AF$freq,
AS.freq = d.AS$freq,
EU.freq = d.EU$freq,
NA.freq = d.NA$freq,
SA.freq = d.SA$freq,
OC.freq = d.OC$freq)
af.nation = unique(hm.country$country[AF])
as.nation = unique(hm.country$country[AS])
eu.nation = unique(hm.country$country[EU])
na.nation = unique(hm.country$country[N.A])
sa.nation = unique(hm.country$country[S.A])
oc.nation = unique(hm.country$country[OC])
continent = c("Africa", "Asia", "Europe", "Northern America", "Southern America", "Oceania")
Pop = c(length(AF),length(AS),length(EU),length(N.A),length(S.A),length(OC))
nation.in.continent =c(length(af.nation),length(as.nation),length(eu.nation),length(na.nation),length(sa.nation),length(oc.nation))
hover = character(6)
for(i in 1:6){
hover[i] = paste( '<b>', continent[i],':<br>',
paste('   ','</b>',hm.region[[i]], ': ', hm.reg.freq[[i]],'% <br>',
collapse=""),
collapse="")
}
pop = rep(Pop,nation.in.continent)
cont = rep(continent,nation.in.continent)
all.nation = c(af.nation,as.nation,eu.nation,na.nation,sa.nation,oc.nation)
rank.text = rep(hover,nation.in.continent)
dataformap = data.frame(Nation = all.nation,
Worker = pop,
Continent = cont,
text = rank.text)
#dim(dataformap)
#View(dataformap)
l = list(color = toRGB("darkgrey"), width = 0.5)
g = list(
showframe = FALSE,
showcoastlines = FALSE,
projection = list(type = 'Mercator')
)
p = plot_geo(dataformap) %>%
add_trace(
z = ~Worker, color = ~Worker, colors = 'Blues',
text = ~text, locations = ~Nation, marker = list(line = l)
) %>%
colorbar(title = 'Number of Amazon MTurk Workers') %>%
layout(
title = 'Top 10 key words of Happy Moments in Each Continent',
geo = g,
autosize = FALSE,
width = 900,
margin = list(t=25, l=0, r=0, d=0)
)
p
p.af = ggplot(data = d.AF,aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "pink")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Africa", x = "Happy Moments",
y = "Frequency")
p.as =  ggplot(data = d.AS,aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "orange")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Asia", x = "Happy Moments",
y = "Frequency")
p.eu =  ggplot(data = d.EU,aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "red")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Europe", x = "Happy Moments",
y = "Frequency")
p.na = ggplot(data = NA_words,aes(x = reorder(word,-n),
y = n))+
geom_bar(stat = "identity", fill = "purple")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Northern America", x = "Happy Moments",
y = "Frequency")
p.sa =  ggplot(data = d.SA,aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "blue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Southern America", x = "Happy Moments",
y = "Frequency")
p.oc =  ggplot(data = d.OC,aes(x = reorder(word,-freq),
y = freq))+
geom_bar(stat = "identity", fill = "lightblue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title = "Oceania", x = "Happy Moments",
y = "Frequency")
ggarrange(p.af, p.as, p.eu, p.na, p.sa, p.oc, ncol = 3, nrow = 2)
hm_lda = LDA(dtm, k = 8, control = list(seed = 1234))
hm_topics = tidy(hm_lda, matrix = "beta")
hm_top_terms = hm_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
hm_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
hm_lda = LDA(dtm, k = 9, control = list(seed = 1234))
hm_topics = tidy(hm_lda, matrix = "beta")
hm_top_terms = hm_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
hm_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
hm_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
### Read data
clean_hm = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'  # Cleaned_hm file
demographic = 'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
clean.hm  =  read_csv(clean_hm)
demog =  read_csv(demographic)
### Preliminary cleaning of text
corpus = VCorpus(VectorSource(clean.hm$cleaned_hm))
corpus = tm_map(corpus, stripWhitespace)  # remove white space
corpus = tm_map(corpus, content_transformer(tolower)) # convert to lower case
corpus = tm_map(corpus, removeWords, stopwords("english")) # remove stop words
corpus = tm_map(corpus, removeWords, character(0)) # remove empty words
corpus = tm_map(corpus, removePunctuation) # remove punctuations
#View(hm.demographic)
### Stem words
stemmed = tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict = tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
data("stop_words")
word = c("happy","ago","yesterday","lot","today","months","month",
"happier","happiest","last","week","past")
stop_words = stop_words %>%
bind_rows(mutate(tibble(word), lexicon = "updated"))
completed = stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>% # seperate stemmed into single words, and mark their id
bind_cols(dict) %>% # column combine dict and stemmed, 1-to-1 matching
anti_join(stop_words, by = c("dictionary" = "word")) # delete meaningless words
completed = completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
HappyMoments = completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
HappyMoments = clean.hm %>%
mutate(id = row_number()) %>%
inner_join(HappyMoments)
### Create 4 columns in HappyMoments for storing demographic information
HappyMoments$country = rep("tba", length(HappyMoments$wid))
HappyMoments$gender = rep("tba", length(HappyMoments$wid))
HappyMoments$marital = rep("tba", length(HappyMoments$wid))
HappyMoments$parenthood = rep("tba", length(HappyMoments$wid))
### matching the demographic information with the correct workers through their wid
for (i in sort(unique(HappyMoments$wid))) {
index = which(HappyMoments$wid == i)
HappyMoments[index,"country"] = demog$country[which(demog$wid == i)]
HappyMoments[index,"gender"] = demog$gender[which(demog$wid == i)]
HappyMoments[index,"marital"] = demog$marital[which(demog$wid == i)]
HappyMoments[index,"parenthood"] = demog$parenthood[which(demog$wid == i)]
}
hm.demographic = HappyMoments[,-c(1,3,4,6,7,8,10)]
# write_csv(hm.demographic, "~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output/hm.demographic.csv")
# write_csv(HappyMoments, "~/Desktop/GR5243 Applied Data Science/Project_1/Spring2019-Proj1-xinyihutay/output/HappyMoment.csv")
comb_hm = vector(mode = "character",length = length(unique(HappyMoments$wid)))
for (i in sort(unique(HappyMoments$wid))) {
index = which(HappyMoments$wid == i)
comb_hm[i] = paste(HappyMoments$text[index], collapse = " ")
}
hm.corpus = VCorpus(VectorSource(comb_hm))
dtm.all = DocumentTermMatrix(hm.corpus)
rowTotals = apply(dtm.all, 1, sum)
dtm  = dtm.all[rowTotals> 0, ]
hm_lda = LDA(dtm, k = 9, control = list(seed = 1234))
hm_topics = tidy(hm_lda, matrix = "beta")
hm_top_terms = hm_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
hm_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
hm_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
p = plot_geo(dataformap) %>%
add_trace(
z = ~Worker, color = ~Worker, colors = 'Blues',
text = ~text, locations = ~Nation, marker = list(line = l)
) %>%
colorbar(title = 'Number of Amazon MTurk Workers') %>%
layout(
title = 'Top 10 key words of Happy Moments in Each Continent',
geo = g,
autosize = FALSE,
width = 800,
margin = list(t=20, l=0, r=0, d=0)
)
p
p = plot_geo(dataformap) %>%
add_trace(
z = ~Worker, color = ~Worker, colors = 'Blues',
text = ~text, locations = ~Nation, marker = list(line = l)
) %>%
colorbar(title = 'Number of Amazon MTurk Workers') %>%
layout(
title = 'Top 10 key words of Happy Moments in Each Continent',
geo = g,
autosize = FALSE,
width = 900,
margin = list(t=20, l=0, r=0, d=0)
)
p
p = plot_geo(dataformap) %>%
add_trace(
z = ~Worker, color = ~Worker, colors = 'Blues',
text = ~text, locations = ~Nation, marker = list(line = l)
) %>%
colorbar(title = 'Number of Amazon MTurk Workers') %>%
layout(
title = 'Top 10 key words of Happy Moments in Each Continent',
geo = g,
autosize = FALSE,
width = 900,
margin = list(t=20, l=0, r=0, d=0)
)
p
wordcloud(tdm_female$term, tdm_female$`sum(count)`,
scale = c(5,0.1),
max.words = 100,
min.freq = 1,
random.order = FALSE,
rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
wordcloud(tdm_male$term, tdm_male$`sum(count)`,
scale = c(5,0.1),
max.words = 100,
min.freq = 1,
random.order = FALSE,
rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
af.nation = unique(hm.country$country[AF])
as.nation = unique(hm.country$country[AS])
eu.nation = unique(hm.country$country[EU])
na.nation = unique(hm.country$country[N.A])
sa.nation = unique(hm.country$country[S.A])
oc.nation = unique(hm.country$country[OC])
continent = c("Africa", "Asia", "Europe", "Northern America", "Southern America", "Oceania")
Pop = c(length(AF),length(AS),length(EU),length(N.A),length(S.A),length(OC))
nation.in.continent =c(length(af.nation),length(as.nation),length(eu.nation),length(na.nation),length(sa.nation),length(oc.nation))
hover = character(6)
for(i in 1:6){
hover[i] = paste( '<b>', continent[i],':<br>',
paste('   ','</b>',hm.region[[i]], ': ', hm.reg.freq[[i]],'% <br>',
collapse=""),
collapse="")
}
pop = rep(Pop,nation.in.continent)
cont = rep(continent,nation.in.continent)
all.nation = c(af.nation,as.nation,eu.nation,na.nation,sa.nation,oc.nation)
rank.text = rep(hover,nation.in.continent)
dataformap = data.frame(Nation = all.nation,
Worker = pop,
Continent = cont,
text = rank.text)
l = list(color = toRGB("darkgrey"), width = 0.5)
g = list(
showframe = FALSE,
showcoastlines = FALSE,
projection = list(type = 'Mercator')
)
p = plot_geo(dataformap) %>%
add_trace(
z = ~Worker, color = ~Worker, colors = 'Blues',
text = ~text, locations = ~Nation, marker = list(line = l)
) %>%
colorbar(title = 'Number of Amazon MTurk Workers') %>%
layout(
title = 'Top 10 key words of Happy Moments in Each Continent',
geo = g,
autosize = FALSE,
width = 900,
margin = list(t=20, l=0, r=0, d=0)
)
p
p
ggarrange(p.af, p.as, p.eu, p.na, p.sa, p.oc, ncol = 3, nrow = 2)
grid.arrange(arrangeGrob(p1, p2))
wordcloud(tdm_yes$term, tdm_yes$`sum(count)`,
scale = c(5,0.1),
max.words = 100,
min.freq = 1,
random.order = FALSE,
rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
wordcloud(tdm_no$term, tdm_no$`sum(count)`,
scale = c(5,0.1),
max.words = 100,
min.freq = 1,
random.order = FALSE,
rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
grid.arrange(arrangeGrob(p3, p4))
ggarrange(p5, p6, p7, p8, p9, nrow = 2, ncol = 3)
wordcloud(tdm_yes$term, tdm_yes$`sum(count)`,
scale = c(5,0.1),
max.words = 100,
min.freq = 1,
random.order = FALSE,
rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
wordcloud(tdm_no$term, tdm_no$`sum(count)`,
scale = c(5,0.1),
max.words = 100,
min.freq = 1,
random.order = FALSE,
rot.per = 0.3,
use.r.layout = T,
random.color = FALSE,
colors = brewer.pal(8,"Accent"))
grid.arrange(arrangeGrob(p3, p4))
ggarrange(p5, p6, p7, p8, p9, nrow = 2, ncol = 3)
p
ggarrange(p.af, p.as, p.eu, p.na, p.sa, p.oc, ncol = 3, nrow = 2)
